{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classical Control\n",
    "## Note the controller's output is disrete which complicated the original intention of using classical PID Control\n",
    "\n",
    "## HyperParameters\n",
    "render = True\n",
    "\n",
    "# https://gym.openai.com/docs\n",
    "\n",
    "# Guesses at observations are: (https://gym.openai.com/evaluations/eval_VQwN8kRESjakUPwJbRlq5Q)\n",
    "# observation[0] = pole speed\n",
    "# observation[1] = pole top pos\n",
    "# observation[2] = pole angle\n",
    "# observation[3] = block speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-07-08 17:14:55,950] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward for Episode 0 is 100.0 / 100\n",
      "Total Reward for Episode 1 is 100.0 / 100\n",
      "Total Reward for Episode 2 is 100.0 / 100\n",
      "Total Reward for Episode 3 is 100.0 / 100\n",
      "Total Reward for Episode 4 is 100.0 / 100\n",
      "Total Reward for Episode 5 is 100.0 / 100\n",
      "Total Reward for Episode 6 is 100.0 / 100\n",
      "Total Reward for Episode 7 is 100.0 / 100\n",
      "Total Reward for Episode 8 is 100.0 / 100\n",
      "Total Reward for Episode 9 is 100.0 / 100\n",
      "Total Reward for Episode 10 is 100.0 / 100\n",
      "Total Reward for Episode 11 is 100.0 / 100\n",
      "Total Reward for Episode 12 is 100.0 / 100\n",
      "Total Reward for Episode 13 is 100.0 / 100\n",
      "Total Reward for Episode 14 is 100.0 / 100\n",
      "Total Reward for Episode 15 is 100.0 / 100\n",
      "Total Reward for Episode 16 is 100.0 / 100\n",
      "Total Reward for Episode 17 is 100.0 / 100\n",
      "Total Reward for Episode 18 is 100.0 / 100\n",
      "Total Reward for Episode 19 is 100.0 / 100\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "env = gym.make('CartPole-v0')\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    total_reward = 0;\n",
    "    total_time = 100;\n",
    "    for t in range(total_time):\n",
    "        if render: env.render()\n",
    "            \n",
    "        if (observation[2] > 0 and observation[3] > -1) or observation[3] > 1:\n",
    "            action = 1 # right\n",
    "        else:\n",
    "            action = 0 # left\n",
    "        \n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "        total_reward += reward\n",
    "        \n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "\n",
    "    print(\"Total Reward for Episode {} is {} / {}\".format(i_episode, total_reward, total_time))\n",
    "        \n",
    "env.monitor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This cell was written by Marco Tamassia; All credit to Marco: https://bitbucket.org/marcotamassia/deep-rl\n",
    "# Ported from Python3 using 3to2: 3to2 -w foo.py\n",
    "# Minro edit as marked below.\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from itertools import izip\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "class RingBuffer(object):\n",
    "    u\"\"\"\n",
    "    A multi-field ring buffer using numpy arrays.\n",
    "\n",
    "    Adapted from https://scimusing.wordpress.com/2013/10/25/ring-buffers-in-pythonnumpy/\n",
    "    \"\"\"\n",
    "    def __init__(self, memory_size, entries_shape):\n",
    "        self.index = 0\n",
    "        self.size = 0\n",
    "        self.data = tuple(\n",
    "            np.zeros((memory_size, size), dtype=dtype)\n",
    "            for size, dtype in entries_shape\n",
    "        )\n",
    "        self.max_size = memory_size\n",
    "\n",
    "    def append(self, row):\n",
    "        for data, new_data in izip(self.data, row):\n",
    "            data[self.index, :] = new_data\n",
    "        self.index = (self.index + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def __get__(self, indices):\n",
    "        return tuple(data[(self.index + indices) % self.max_size, :] for data in self.data)\n",
    "\n",
    "    def get_random_entries(self, n):\n",
    "        indices = np.random.randint(0, self.size, n)\n",
    "        return tuple(data[indices, :] for data in self.data)\n",
    "\n",
    "\n",
    "class Experience(object):\n",
    "    u\"\"\"\n",
    "    Experience pool, used to generate batches of random past experience.\n",
    "    \"\"\"\n",
    "    def __init__(self, state_size, memory_size, discount):\n",
    "        self.discount = discount\n",
    "        self.memory = RingBuffer(\n",
    "            memory_size=memory_size,\n",
    "            entries_shape=(\n",
    "                (state_size, float),\n",
    "                (1, int),\n",
    "                (1, float),\n",
    "                (state_size, float),\n",
    "                (1, bool)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def remember(self, state, action, reward, new_state, game_over):\n",
    "        self.memory.append((state, action, reward, new_state, game_over))\n",
    "\n",
    "    def get_batch(self, model, batch_size):\n",
    "        n_rows = min(self.memory.size, batch_size)\n",
    "\n",
    "        S, A, R, NS, GO = self.memory.get_random_entries(n_rows)\n",
    "        A, R, NGO = A.flatten(), R.flatten(), ~GO.flatten()\n",
    "        inputs = S\n",
    "        targets = model.predict(S)\n",
    "        targets[np.arange(len(A)), A] = R\n",
    "        targets[np.where(NGO), A[NGO]] += self.discount * np.max(model.predict(NS[NGO,:]),axis=1)\n",
    "        return inputs, targets\n",
    "\n",
    "\n",
    "def make_net(num_actions, state_size, hidden_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_size, input_shape=(state_size,)))\n",
    "    model.add(Activation(u'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_actions))\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) # Added\n",
    "    model.compile(optimizer=sgd, loss=u\"MSE\")\n",
    "    return model, sgd # Added sgd\n",
    "\n",
    "\n",
    "def do_the_thing():\n",
    "    episodes = 500 # Changed from 1000 to 500\n",
    "    batch_size = 100\n",
    "    epsilon = 0.1\n",
    "    epsilon_decay = 1e-03\n",
    "    hidden_size = 1000\n",
    "    experience_pool_size = 3000\n",
    "    discount = 0.99\n",
    "\n",
    "    env = gym.make(u\"CartPole-v0\")\n",
    "    exp = Experience(env.state.size, experience_pool_size, discount)\n",
    "    model, sgd = make_net(\n",
    "        num_actions=env.action_space.n,\n",
    "        state_size=env.state.size,\n",
    "        hidden_size=hidden_size\n",
    "    )\n",
    "\n",
    "    for ep_n in xrange(episodes):\n",
    "        state = env.reset()\n",
    "        game_over = False\n",
    "        loss, ret, steps = 0.0, 0, 0\n",
    "        ret = 0\n",
    "        while not game_over:\n",
    "            env.render()\n",
    "\n",
    "            # Choose an epsilon-greedy action\n",
    "            if random.random() <= epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # print(model.predict(state[np.newaxis,:])[0])\n",
    "                action = np.argmax(model.predict(state[np.newaxis,:])[0])\n",
    "            epsilon *= (1 - epsilon_decay)\n",
    "\n",
    "            # Collect experience\n",
    "            new_state, reward, game_over, info = env.step(action)\n",
    "            reward = -1 if game_over else 1 - abs(new_state[2])*10\n",
    "            exp.remember(state, action, reward, new_state, game_over)\n",
    "            state = new_state\n",
    "\n",
    "            # Train model and update stats\n",
    "            inputs, targets = exp.get_batch(model, batch_size=batch_size)\n",
    "            loss += model.train_on_batch(inputs, targets)\n",
    "            ret += reward\n",
    "            steps += 1\n",
    "        print u\"Episode {:03d}/{:03d} | Loss {:.3f} | Return {:.3f} | Steps {:d}\".format(ep_n+1, episodes, loss, ret, steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-07-08 17:40:17,871] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 001/500 | Loss 1.349 | Return -0.024 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 002/500 | Loss 1.938 | Return 2.450 | Steps 11\n",
      "0.00999999977648\n",
      "Episode 003/500 | Loss 1.309 | Return 2.200 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 004/500 | Loss 1.264 | Return 0.896 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 005/500 | Loss 1.364 | Return 2.788 | Steps 11\n",
      "0.00999999977648\n",
      "Episode 006/500 | Loss 1.114 | Return 2.927 | Steps 11\n",
      "0.00999999977648\n",
      "Episode 007/500 | Loss 0.932 | Return 1.107 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 008/500 | Loss 1.382 | Return 0.816 | Steps 11\n",
      "0.00999999977648\n",
      "Episode 009/500 | Loss 0.986 | Return 0.221 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 010/500 | Loss 1.290 | Return 1.317 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 011/500 | Loss 1.319 | Return 1.924 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 012/500 | Loss 1.480 | Return 2.150 | Steps 12\n",
      "0.00999999977648\n",
      "Episode 013/500 | Loss 1.304 | Return 2.883 | Steps 12\n",
      "0.00999999977648\n",
      "Episode 014/500 | Loss 2.506 | Return 3.975 | Steps 14\n",
      "0.00999999977648\n",
      "Episode 015/500 | Loss 1.555 | Return 0.396 | Steps 11\n",
      "0.00999999977648\n",
      "Episode 016/500 | Loss 1.414 | Return 1.456 | Steps 11\n",
      "0.00999999977648\n",
      "Episode 017/500 | Loss 1.262 | Return -1.121 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 018/500 | Loss 1.768 | Return 1.807 | Steps 14\n",
      "0.00999999977648\n",
      "Episode 019/500 | Loss 1.755 | Return 1.347 | Steps 13\n",
      "0.00999999977648\n",
      "Episode 020/500 | Loss 1.840 | Return 2.403 | Steps 14\n",
      "0.00999999977648\n",
      "Episode 021/500 | Loss 1.441 | Return -1.249 | Steps 11\n",
      "0.00999999977648\n",
      "Episode 022/500 | Loss 1.399 | Return 1.194 | Steps 12\n",
      "0.00999999977648\n",
      "Episode 023/500 | Loss 1.445 | Return 1.267 | Steps 12\n",
      "0.00999999977648\n",
      "Episode 024/500 | Loss 1.547 | Return 1.788 | Steps 13\n",
      "0.00999999977648\n",
      "Episode 025/500 | Loss 1.723 | Return 1.959 | Steps 13\n",
      "0.00999999977648\n",
      "Episode 026/500 | Loss 1.582 | Return -1.922 | Steps 11\n",
      "0.00999999977648\n",
      "Episode 027/500 | Loss 1.777 | Return 1.289 | Steps 14\n",
      "0.00999999977648\n",
      "Episode 028/500 | Loss 1.868 | Return 2.185 | Steps 15\n",
      "0.00999999977648\n",
      "Episode 029/500 | Loss 1.493 | Return -0.416 | Steps 12\n",
      "0.00999999977648\n",
      "Episode 030/500 | Loss 1.970 | Return 2.044 | Steps 15\n",
      "0.00999999977648\n",
      "Episode 031/500 | Loss 1.361 | Return -0.646 | Steps 11\n",
      "0.00999999977648\n",
      "Episode 032/500 | Loss 1.912 | Return 2.057 | Steps 15\n",
      "0.00999999977648\n",
      "Episode 033/500 | Loss 3.082 | Return 5.264 | Steps 20\n",
      "0.00999999977648\n",
      "Episode 034/500 | Loss 2.361 | Return 1.907 | Steps 17\n",
      "0.00999999977648\n",
      "Episode 035/500 | Loss 2.071 | Return 2.401 | Steps 15\n",
      "0.00999999977648\n",
      "Episode 036/500 | Loss 2.165 | Return 1.200 | Steps 14\n",
      "0.00999999977648\n",
      "Episode 037/500 | Loss 2.662 | Return 2.204 | Steps 17\n",
      "0.00999999977648\n",
      "Episode 038/500 | Loss 2.117 | Return 0.501 | Steps 15\n",
      "0.00999999977648\n",
      "Episode 039/500 | Loss 2.065 | Return 1.131 | Steps 15\n",
      "0.00999999977648\n",
      "Episode 040/500 | Loss 2.136 | Return -2.219 | Steps 14\n",
      "0.00999999977648\n",
      "Episode 041/500 | Loss 2.194 | Return -1.858 | Steps 14\n",
      "0.00999999977648\n",
      "Episode 042/500 | Loss 2.440 | Return -0.180 | Steps 17\n",
      "0.00999999977648\n",
      "Episode 043/500 | Loss 2.220 | Return -2.050 | Steps 16\n",
      "0.00999999977648\n",
      "Episode 044/500 | Loss 2.650 | Return -2.161 | Steps 19\n",
      "0.00999999977648\n",
      "Episode 045/500 | Loss 2.658 | Return -4.580 | Steps 19\n",
      "0.00999999977648\n",
      "Episode 046/500 | Loss 4.255 | Return -1.702 | Steps 28\n",
      "0.00999999977648\n",
      "Episode 047/500 | Loss 3.101 | Return -6.874 | Steps 22\n",
      "0.00999999977648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-07-08 17:40:29,717] Observation '[ 2.45108652  2.36256872  0.09687993  0.03139206]' is not contained within observation space 'Box(4,)'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 048/500 | Loss 16.409 | Return -17.310 | Steps 105\n",
      "0.00999999977648\n",
      "Episode 049/500 | Loss 23.231 | Return 47.928 | Steps 122\n",
      "0.00999999977648\n",
      "Episode 050/500 | Loss 11.790 | Return 20.335 | Steps 38\n",
      "0.00999999977648\n",
      "Episode 051/500 | Loss 6.207 | Return 0.527 | Steps 13\n",
      "0.00999999977648\n",
      "Episode 052/500 | Loss 8.541 | Return 2.389 | Steps 11\n",
      "0.00999999977648\n",
      "Episode 053/500 | Loss 9.500 | Return 1.359 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 054/500 | Loss 15.141 | Return 3.575 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 055/500 | Loss 21.992 | Return 0.728 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 056/500 | Loss 117.714 | Return 3.425 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 057/500 | Loss 176.230 | Return 3.177 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 058/500 | Loss 136.694 | Return 6.820 | Steps 14\n",
      "0.00999999977648\n",
      "Episode 059/500 | Loss 231.249 | Return 1.179 | Steps 12\n",
      "0.00999999977648\n",
      "Episode 060/500 | Loss 49.024 | Return 7.061 | Steps 24\n",
      "0.00999999977648\n",
      "Episode 061/500 | Loss 28.627 | Return 5.575 | Steps 21\n",
      "0.00999999977648\n",
      "Episode 062/500 | Loss 38.672 | Return 0.134 | Steps 18\n",
      "0.00999999977648\n",
      "Episode 063/500 | Loss 95.242 | Return 38.442 | Steps 85\n",
      "0.00999999977648\n",
      "Episode 064/500 | Loss 498.140 | Return 27.268 | Steps 134\n",
      "0.00999999977648\n",
      "Episode 065/500 | Loss 181.459 | Return 9.347 | Steps 37\n",
      "0.00999999977648\n",
      "Episode 066/500 | Loss 270.163 | Return 30.434 | Steps 50\n",
      "0.00999999977648\n",
      "Episode 067/500 | Loss 959.437 | Return 79.253 | Steps 175\n",
      "0.00999999977648\n",
      "Episode 068/500 | Loss 1110.219 | Return 12.851 | Steps 35\n",
      "0.00999999977648\n",
      "Episode 069/500 | Loss nan | Return 34.401 | Steps 58\n",
      "0.00999999977648\n",
      "Episode 070/500 | Loss nan | Return 3.046 | Steps 11\n",
      "0.00999999977648\n",
      "Episode 071/500 | Loss nan | Return 2.815 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 072/500 | Loss nan | Return 1.395 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 073/500 | Loss nan | Return 1.023 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 074/500 | Loss nan | Return 1.907 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 075/500 | Loss nan | Return 2.695 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 076/500 | Loss nan | Return 2.056 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 077/500 | Loss nan | Return 1.111 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 078/500 | Loss nan | Return 0.514 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 079/500 | Loss nan | Return 3.191 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 080/500 | Loss nan | Return 3.136 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 081/500 | Loss nan | Return -0.212 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 082/500 | Loss nan | Return 0.827 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 083/500 | Loss nan | Return 0.884 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 084/500 | Loss nan | Return 2.105 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 085/500 | Loss nan | Return 3.004 | Steps 11\n",
      "0.00999999977648\n",
      "Episode 086/500 | Loss nan | Return 3.334 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 087/500 | Loss nan | Return 2.916 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 088/500 | Loss nan | Return 1.412 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 089/500 | Loss nan | Return 3.226 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 090/500 | Loss nan | Return 3.884 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 091/500 | Loss nan | Return 3.718 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 092/500 | Loss nan | Return 0.317 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 093/500 | Loss nan | Return 0.938 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 094/500 | Loss nan | Return 1.991 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 095/500 | Loss nan | Return 2.209 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 096/500 | Loss nan | Return 2.454 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 097/500 | Loss nan | Return 3.812 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 098/500 | Loss nan | Return 3.464 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 099/500 | Loss nan | Return 0.427 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 100/500 | Loss nan | Return 3.083 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 101/500 | Loss nan | Return -0.031 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 102/500 | Loss nan | Return 2.847 | Steps 11\n",
      "0.00999999977648\n",
      "Episode 103/500 | Loss nan | Return 1.276 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 104/500 | Loss nan | Return 3.709 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 105/500 | Loss nan | Return 3.518 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 106/500 | Loss nan | Return 3.757 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 107/500 | Loss nan | Return 3.842 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 108/500 | Loss nan | Return 1.286 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 109/500 | Loss nan | Return 0.458 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 110/500 | Loss nan | Return 3.268 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 111/500 | Loss nan | Return -0.058 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 112/500 | Loss nan | Return 2.709 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 113/500 | Loss nan | Return 3.858 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 114/500 | Loss nan | Return 2.417 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 115/500 | Loss nan | Return 3.652 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 116/500 | Loss nan | Return 1.490 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 117/500 | Loss nan | Return 3.246 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 118/500 | Loss nan | Return 3.655 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 119/500 | Loss nan | Return 2.915 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 120/500 | Loss nan | Return 3.114 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 121/500 | Loss nan | Return 3.048 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 122/500 | Loss nan | Return 3.662 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 123/500 | Loss nan | Return 3.415 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 124/500 | Loss nan | Return 0.828 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 125/500 | Loss nan | Return 1.294 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 126/500 | Loss nan | Return 3.103 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 127/500 | Loss nan | Return 1.351 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 128/500 | Loss nan | Return 0.817 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 129/500 | Loss nan | Return 2.958 | Steps 11\n",
      "0.00999999977648\n",
      "Episode 130/500 | Loss nan | Return 0.501 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 131/500 | Loss nan | Return 0.564 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 132/500 | Loss nan | Return 3.536 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 133/500 | Loss nan | Return 3.009 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 134/500 | Loss nan | Return 2.926 | Steps 11\n",
      "0.00999999977648\n",
      "Episode 135/500 | Loss nan | Return 2.044 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 136/500 | Loss nan | Return 3.048 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 137/500 | Loss nan | Return 1.289 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 138/500 | Loss nan | Return 3.937 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 139/500 | Loss nan | Return 2.853 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 140/500 | Loss nan | Return 1.980 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 141/500 | Loss nan | Return 3.745 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 142/500 | Loss nan | Return 3.346 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 143/500 | Loss nan | Return 0.073 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 144/500 | Loss nan | Return 2.987 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 145/500 | Loss nan | Return 0.546 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 146/500 | Loss nan | Return 2.602 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 147/500 | Loss nan | Return 2.451 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 148/500 | Loss nan | Return 1.647 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 149/500 | Loss nan | Return 0.404 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 150/500 | Loss nan | Return -0.069 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 151/500 | Loss nan | Return 2.937 | Steps 11\n",
      "0.00999999977648\n",
      "Episode 152/500 | Loss nan | Return -0.079 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 153/500 | Loss nan | Return 0.043 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 154/500 | Loss nan | Return 2.805 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 155/500 | Loss nan | Return 0.568 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 156/500 | Loss nan | Return 1.274 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 157/500 | Loss nan | Return 1.920 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 158/500 | Loss nan | Return 2.929 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 159/500 | Loss nan | Return 0.552 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 160/500 | Loss nan | Return 3.275 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 161/500 | Loss nan | Return 3.010 | Steps 11\n",
      "0.00999999977648\n",
      "Episode 162/500 | Loss nan | Return 3.046 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 163/500 | Loss nan | Return 3.807 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 164/500 | Loss nan | Return 3.287 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 165/500 | Loss nan | Return 3.541 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 166/500 | Loss nan | Return 3.120 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 167/500 | Loss nan | Return 3.204 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 168/500 | Loss nan | Return 2.413 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 169/500 | Loss nan | Return 1.445 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 170/500 | Loss nan | Return 2.752 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 171/500 | Loss nan | Return 3.435 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 172/500 | Loss nan | Return 0.106 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 173/500 | Loss nan | Return 3.322 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 174/500 | Loss nan | Return 2.519 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 175/500 | Loss nan | Return 1.116 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 176/500 | Loss nan | Return 3.750 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 177/500 | Loss nan | Return 1.351 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 178/500 | Loss nan | Return 2.463 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 179/500 | Loss nan | Return 2.280 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 180/500 | Loss nan | Return 3.592 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 181/500 | Loss nan | Return 3.327 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 182/500 | Loss nan | Return 2.402 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 183/500 | Loss nan | Return 2.766 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 184/500 | Loss nan | Return 0.682 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 185/500 | Loss nan | Return 3.710 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 186/500 | Loss nan | Return 3.822 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 187/500 | Loss nan | Return 2.569 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 188/500 | Loss nan | Return 2.516 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 189/500 | Loss nan | Return 0.762 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 190/500 | Loss nan | Return 3.392 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 191/500 | Loss nan | Return 1.736 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 192/500 | Loss nan | Return 3.829 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 193/500 | Loss nan | Return 3.561 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 194/500 | Loss nan | Return 2.669 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 195/500 | Loss nan | Return 3.186 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 196/500 | Loss nan | Return 2.037 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 197/500 | Loss nan | Return 0.157 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 198/500 | Loss nan | Return 1.066 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 199/500 | Loss nan | Return 0.432 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 200/500 | Loss nan | Return 2.791 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 201/500 | Loss nan | Return 3.273 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 202/500 | Loss nan | Return 2.491 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 203/500 | Loss nan | Return 2.517 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 204/500 | Loss nan | Return 1.640 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 205/500 | Loss nan | Return 2.116 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 206/500 | Loss nan | Return 0.725 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 207/500 | Loss nan | Return 3.570 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 208/500 | Loss nan | Return 2.560 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 209/500 | Loss nan | Return 2.498 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 210/500 | Loss nan | Return 1.479 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 211/500 | Loss nan | Return 3.198 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 212/500 | Loss nan | Return 2.945 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 213/500 | Loss nan | Return 3.711 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 214/500 | Loss nan | Return 2.568 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 215/500 | Loss nan | Return 2.122 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 216/500 | Loss nan | Return 3.366 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 217/500 | Loss nan | Return 3.286 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 218/500 | Loss nan | Return 0.804 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 219/500 | Loss nan | Return 1.632 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 220/500 | Loss nan | Return 2.447 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 221/500 | Loss nan | Return 2.695 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 222/500 | Loss nan | Return 0.656 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 223/500 | Loss nan | Return 3.164 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 224/500 | Loss nan | Return 1.224 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 225/500 | Loss nan | Return 0.731 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 226/500 | Loss nan | Return 3.490 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 227/500 | Loss nan | Return -0.059 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 228/500 | Loss nan | Return 0.031 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 229/500 | Loss nan | Return 2.661 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 230/500 | Loss nan | Return 2.661 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 231/500 | Loss nan | Return 2.551 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 232/500 | Loss nan | Return 3.761 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 233/500 | Loss nan | Return 2.716 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 234/500 | Loss nan | Return 0.586 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 235/500 | Loss nan | Return 1.595 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 236/500 | Loss nan | Return 0.180 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 237/500 | Loss nan | Return 0.995 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 238/500 | Loss nan | Return 3.614 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 239/500 | Loss nan | Return 2.439 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 240/500 | Loss nan | Return 3.237 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 241/500 | Loss nan | Return 3.496 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 242/500 | Loss nan | Return 2.605 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 243/500 | Loss nan | Return 1.987 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 244/500 | Loss nan | Return 3.293 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 245/500 | Loss nan | Return 3.521 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 246/500 | Loss nan | Return 2.879 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 247/500 | Loss nan | Return 0.713 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 248/500 | Loss nan | Return 3.506 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 249/500 | Loss nan | Return 3.637 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 250/500 | Loss nan | Return 2.179 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 251/500 | Loss nan | Return 3.483 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 252/500 | Loss nan | Return 2.404 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 253/500 | Loss nan | Return 1.199 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 254/500 | Loss nan | Return 2.441 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 255/500 | Loss nan | Return 2.639 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 256/500 | Loss nan | Return 3.820 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 257/500 | Loss nan | Return 3.530 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 258/500 | Loss nan | Return 3.911 | Steps 10\n",
      "0.00999999977648\n",
      "Episode 259/500 | Loss nan | Return 0.682 | Steps 8\n",
      "0.00999999977648\n",
      "Episode 260/500 | Loss nan | Return 3.100 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 261/500 | Loss nan | Return 1.958 | Steps 9\n",
      "0.00999999977648\n",
      "Episode 262/500 | Loss nan | Return 1.708 | Steps 9\n",
      "0.00999999977648\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3cd90a5fd01e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdo_the_thing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-bd5aa1db4a36>\u001b[0m in \u001b[0;36mdo_the_thing\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# Train model and update stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0msteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[1;32m    504\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                                          class_weight=class_weight)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     def test_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0mdt_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdt_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mprofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvm_call_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdt_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "do_the_thing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
